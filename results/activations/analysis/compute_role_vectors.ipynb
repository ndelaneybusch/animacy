{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0e48db",
   "metadata": {},
   "source": [
    "# Role Vector Analysis\n",
    "\n",
    "This notebook computes role vectors for various metrics using activation summaries and response ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd35587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home/nate/repos/animacy/results/activations/analysis\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"CWD: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65109d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations Dir: /home/nate/repos/animacy/results/activations/data/Qwen3-30B-A3B-Instruct-2507\n",
      "Ratings Path: /home/nate/repos/animacy/results/ratings/data/Qwen3-30B-A3B-Instruct-2507/response_ratings.csv\n",
      "Output Dir: /home/nate/repos/animacy/results/steering/data/Qwen3-30B-A3B-Instruct-2507\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "ACTIVATIONS_DIR = Path(\"../data/Qwen3-30B-A3B-Instruct-2507\")\n",
    "RATINGS_PATH = Path(\"../../ratings/data/Qwen3-30B-A3B-Instruct-2507/response_ratings.csv\")\n",
    "OUTPUT_DIR = Path(\"../../steering/data/Qwen3-30B-A3B-Instruct-2507\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Activations Dir: {ACTIVATIONS_DIR.resolve()}\")\n",
    "print(f\"Ratings Path: {RATINGS_PATH.resolve()}\")\n",
    "print(f\"Output Dir: {OUTPUT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0892536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6300 ratings.\n",
      "Trials with deviations: 617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13552/3053222701.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ratings[col] = ratings[col].fillna(False).astype(bool)\n",
      "/tmp/ipykernel_13552/3053222701.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ratings[col] = ratings[col].fillna(False).astype(bool)\n",
      "/tmp/ipykernel_13552/3053222701.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ratings[col] = ratings[col].fillna(False).astype(bool)\n",
      "/tmp/ipykernel_13552/3053222701.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ratings[col] = ratings[col].fillna(False).astype(bool)\n"
     ]
    }
   ],
   "source": [
    "# Load Ratings\n",
    "if not RATINGS_PATH.exists():\n",
    "    print(f\"ERROR: Ratings file not found at {RATINGS_PATH.resolve()}\")\n",
    "else:\n",
    "    ratings = pd.read_csv(RATINGS_PATH)\n",
    "    print(f\"Loaded {len(ratings)} ratings.\")\n",
    "\n",
    "    # Identify deviation columns\n",
    "    deviation_cols = [\"assistant_refusal\", \"role_refusal\", \"identify_as_assistant\", \"deny_internal_experience\"]\n",
    "    # Ensure boolean\n",
    "    for col in deviation_cols:\n",
    "        if col in ratings.columns:\n",
    "            ratings[col] = ratings[col].fillna(False).astype(bool)\n",
    "\n",
    "    ratings[\"has_deviation\"] = ratings[deviation_cols].any(axis=1)\n",
    "    print(f\"Trials with deviations: {ratings['has_deviation'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6851b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_activations(base_dir, sys_type=\"with_sys\"):\n",
    "    data = []\n",
    "    summaries_dir = base_dir / sys_type / \"summaries\"\n",
    "    \n",
    "    print(f\"Checking summaries dir: {summaries_dir.resolve()}\")\n",
    "    if not summaries_dir.exists():\n",
    "        print(f\"Warning: {summaries_dir} does not exist.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    files = list(summaries_dir.glob(\"*.json\"))\n",
    "    print(f\"Loading {len(files)} files from {sys_type}...\")\n",
    "    \n",
    "    for file_path in tqdm(files):\n",
    "        filename = file_path.name\n",
    "        try:\n",
    "            stem = file_path.stem\n",
    "            parts = stem.split(\"_\")\n",
    "            \n",
    "            layer_part = parts[-1]\n",
    "            layer = int(layer_part.replace(\"layer\", \"\"))\n",
    "            sample_idx = int(parts[-2])\n",
    "            \n",
    "            entry = {\n",
    "                \"sys_type\": sys_type,\n",
    "                \"filename_stem\": \"_\".join(parts),\n",
    "                \"sample_idx\": sample_idx,\n",
    "                \"layer\": layer,\n",
    "            }\n",
    "            \n",
    "            with open(file_path, \"r\") as f:\n",
    "                content = json.load(f)\n",
    "            \n",
    "            for key, value in content.items():\n",
    "                if isinstance(value, list):\n",
    "                    entry[key] = np.array(value)\n",
    "            \n",
    "            data.append(entry)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {filename}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836b515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known roles: 125\n",
      "Known tasks: 10\n"
     ]
    }
   ],
   "source": [
    "# Get unique roles and tasks from ratings to help parsing\n",
    "known_roles = set(ratings[\"role_name\"].dropna().unique())\n",
    "known_tasks = set(ratings[\"task_name\"].dropna().unique())\n",
    "\n",
    "print(f\"Known roles: {len(known_roles)}\")\n",
    "print(f\"Known tasks: {len(known_tasks)}\")\n",
    "\n",
    "def parse_role_task(filename_stem, known_roles, known_tasks):\n",
    "    # Ensure r is string\n",
    "    role_map = {str(r).replace(\" \", \"_\"): str(r) for r in known_roles}\n",
    "    best_role = None\n",
    "    best_task = None\n",
    "    \n",
    "    for r_underscore in role_map:\n",
    "        if filename_stem.startswith(r_underscore):\n",
    "            remainder = filename_stem[len(r_underscore):]\n",
    "            if remainder.startswith(\"_\"):\n",
    "                task_part = remainder[1:]\n",
    "                if task_part in known_tasks:\n",
    "                    if best_role is None or len(r_underscore) > len(best_role.replace(\" \", \"_\")):\n",
    "                        best_role = role_map[r_underscore]\n",
    "                        best_task = task_part\n",
    "    \n",
    "    if best_role:\n",
    "        return best_role, best_task\n",
    "    \n",
    "    parts = filename_stem.split(\"_\", 1)\n",
    "    if len(parts) == 2:\n",
    "        return parts[0], parts[1]\n",
    "    return filename_stem, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd577e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking summaries dir: /home/nate/repos/animacy/results/activations/data/Qwen3-30B-A3B-Instruct-2507/with_sys/summaries\n",
      "Loading 25200 files from with_sys...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f642a26d6c1646a6b5c87f33bc52c742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25200 with_sys activations.\n",
      "   sys_type                       filename_stem  sample_idx  layer  \\\n",
      "0  with_sys          shadow_favorites_4_layer26           4     26   \n",
      "1  with_sys  blouse_meaningful_moment_2_layer38           2     38   \n",
      "2  with_sys   emperor_meaning_of_life_1_layer38           1     38   \n",
      "3  with_sys          weed_future_self_3_layer34           3     34   \n",
      "4  with_sys               sock_dreams_3_layer34           3     34   \n",
      "\n",
      "                                   avg_system_prompt  \\\n",
      "0  [0.05712890625, 0.640625, -0.018798828125, 0.0...   \n",
      "1  [0.038818359375, 0.6015625, 0.006500244140625,...   \n",
      "2  [0.048095703125, 0.55859375, -0.1591796875, 0....   \n",
      "3  [0.107421875, 0.77734375, 0.2470703125, -0.005...   \n",
      "4  [0.0810546875, 0.72265625, 0.080078125, -0.046...   \n",
      "\n",
      "                                     avg_user_prompt  \\\n",
      "0  [0.06982421875, 0.40234375, 0.040771484375, -0...   \n",
      "1  [-0.10791015625, 0.345703125, -0.197265625, -0...   \n",
      "2  [-0.1640625, 0.318359375, 0.002166748046875, -...   \n",
      "3  [0.1962890625, 0.5390625, 0.23828125, 0.021972...   \n",
      "4  [-0.0888671875, 0.45703125, 0.0439453125, 0.14...   \n",
      "\n",
      "                                        avg_response  \\\n",
      "0  [-0.1279296875, 0.197265625, -0.09521484375, -...   \n",
      "1  [0.1318359375, -0.003936767578125, -0.20703125...   \n",
      "2  [0.43359375, -0.203125, -0.03564453125, -0.161...   \n",
      "3  [-0.1865234375, -0.2333984375, 0.0537109375, -...   \n",
      "4  [-0.2578125, -0.271484375, 0.1015625, -0.06542...   \n",
      "\n",
      "                        avg_response_first_10_tokens  \\\n",
      "0  [-0.078125, 0.328125, -0.10400390625, -0.07763...   \n",
      "1  [0.09130859375, -0.056884765625, -0.283203125,...   \n",
      "2  [0.234375, 0.126953125, 0.2099609375, 0.178710...   \n",
      "3  [-0.024658203125, 0.61328125, -0.111328125, -0...   \n",
      "4  [-0.10009765625, 0.2734375, 0.026123046875, -0...   \n",
      "\n",
      "                                             at_role  \\\n",
      "0  [-0.55078125, 0.73828125, 0.055908203125, 0.14...   \n",
      "1  [0.361328125, 0.001953125, -0.032958984375, 0....   \n",
      "2  [-0.173828125, 0.671875, -0.068359375, 0.42968...   \n",
      "3  [0.05615234375, 0.490234375, 0.75, 0.2734375, ...   \n",
      "4  [-0.07275390625, 0.361328125, 0.10595703125, 0...   \n",
      "\n",
      "                                      at_role_period  \\\n",
      "0  [-0.2177734375, 1.3828125, 0.095703125, 0.3125...   \n",
      "1  [-0.28125, 1.828125, -0.408203125, -0.04833984...   \n",
      "2  [-0.765625, 1.296875, -0.2470703125, -0.201171...   \n",
      "3  [-0.068359375, 1.765625, 0.1572265625, -0.0307...   \n",
      "4  [-0.07275390625, 1.6171875, -0.034912109375, 0...   \n",
      "\n",
      "                                at_end_system_prompt  \\\n",
      "0  [-0.1220703125, 0.365234375, -0.0517578125, -0...   \n",
      "1  [-0.01611328125, 0.41015625, -1.015625, -0.75,...   \n",
      "2  [-0.0380859375, 0.326171875, -1.0078125, -0.96...   \n",
      "3  [-0.0927734375, 0.357421875, -0.203125, -0.472...   \n",
      "4  [-0.1015625, 0.365234375, -0.25390625, -0.4238...   \n",
      "\n",
      "                                  at_end_user_prompt  \\\n",
      "0  [-0.27734375, 0.146484375, 0.015625, -0.261718...   \n",
      "1  [-0.51953125, 0.77734375, -0.625, -0.44921875,...   \n",
      "2  [-0.0068359375, 0.55078125, -0.6953125, -0.886...   \n",
      "3  [-0.30859375, 0.138671875, -0.1103515625, -0.5...   \n",
      "4  [-0.123046875, 0.193359375, -0.02685546875, -0...   \n",
      "\n",
      "                             at_start_agent_response     role  \\\n",
      "0  [-0.1357421875, -0.3828125, -0.2421875, 0.0952...   shadow   \n",
      "1  [-0.16015625, -0.484375, -0.1015625, -0.679687...   blouse   \n",
      "2  [-0.193359375, -0.345703125, -0.37109375, -0.5...  emperor   \n",
      "3  [-0.30859375, -0.56640625, -0.173828125, -0.08...     weed   \n",
      "4  [-0.34765625, -0.412109375, -0.1484375, -0.025...     sock   \n",
      "\n",
      "                          task  \n",
      "0          favorites_4_layer26  \n",
      "1  meaningful_moment_2_layer38  \n",
      "2    meaning_of_life_1_layer38  \n",
      "3        future_self_3_layer34  \n",
      "4             dreams_3_layer34  \n"
     ]
    }
   ],
   "source": [
    "# Load with_sys activations\n",
    "df_with_sys = load_activations(ACTIVATIONS_DIR, \"with_sys\")\n",
    "\n",
    "if df_with_sys.empty:\n",
    "    print(\"ERROR: df_with_sys is empty!\")\n",
    "else:\n",
    "    # Parse roles and tasks\n",
    "    parsed = df_with_sys[\"filename_stem\"].apply(lambda x: parse_role_task(x, known_roles, known_tasks))\n",
    "    df_with_sys[\"role\"] = parsed.apply(lambda x: x[0])\n",
    "    df_with_sys[\"task\"] = parsed.apply(lambda x: x[1])\n",
    "\n",
    "    print(f\"Loaded {len(df_with_sys)} with_sys activations.\")\n",
    "    print(df_with_sys.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant roles definition\n",
    "assistant_roles = [\"AI\", \"assistant\", \"AI assistant\", \"helpful assistant\"]\n",
    "\n",
    "def get_assistant_baseline(df, metric_col, use_all_trials=True):\n",
    "    if df.empty:\n",
    "        return None\n",
    "    mask = df[\"role\"].isin(assistant_roles)\n",
    "    assist_df = df[mask]\n",
    "    \n",
    "    if assist_df.empty:\n",
    "        print(f\"Warning: No assistant roles found for baseline in {metric_col}.\")\n",
    "        return None\n",
    "    \n",
    "    baseline = {}\n",
    "    layers = assist_df[\"layer\"].unique()\n",
    "    \n",
    "    for layer in layers:\n",
    "        layer_data = assist_df[assist_df[\"layer\"] == layer][metric_col]\n",
    "        vectors = np.stack(layer_data.values)\n",
    "        baseline[layer] = np.mean(vectors, axis=0)\n",
    "        \n",
    "    return baseline\n",
    "\n",
    "def compute_and_save_metric(df, metric_col, metric_name, filter_deviations=False, assistant_baseline=None, output_dir=OUTPUT_DIR):\n",
    "    if df.empty:\n",
    "        print(f\"Skipping {metric_name} because df is empty.\")\n",
    "        return\n",
    "\n",
    "    if filter_deviations:\n",
    "        df[\"sample_idx\"] = df[\"sample_idx\"].astype(int)\n",
    "        ratings[\"sample_idx\"] = ratings[\"sample_idx\"].astype(int)\n",
    "        \n",
    "        merged = pd.merge(\n",
    "            df,\n",
    "            ratings[[\"role_name\", \"task_name\", \"sample_idx\", \"has_deviation\"]],\n",
    "            left_on=[\"role\", \"task\", \"sample_idx\"],\n",
    "            right_on=[\"role_name\", \"task_name\", \"sample_idx\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "        merged[\"has_deviation\"] = merged[\"has_deviation\"].fillna(False)\n",
    "        keep_mask = (~merged[\"has_deviation\"]) | (merged[\"role\"].isin(assistant_roles))\n",
    "        working_df = merged[keep_mask].copy()\n",
    "        print(f\"Filtered {metric_name}: {len(df)} -> {len(working_df)} rows.\")\n",
    "    else:\n",
    "        working_df = df.copy()\n",
    "        \n",
    "    role_vectors = {}\n",
    "    roles = working_df[\"role\"].unique()\n",
    "    layers = working_df[\"layer\"].unique()\n",
    "    \n",
    "    for role in tqdm(roles, desc=f\"Computing {metric_name}\"):\n",
    "        role_vectors[role] = {}\n",
    "        role_df = working_df[working_df[\"role\"] == role]\n",
    "        \n",
    "        for layer in layers:\n",
    "            layer_data = role_df[role_df[\"layer\"] == layer][metric_col]\n",
    "            if layer_data.empty:\n",
    "                continue\n",
    "                \n",
    "            vectors = np.stack(layer_data.values)\n",
    "            avg_vector = np.mean(vectors, axis=0)\n",
    "            \n",
    "            if assistant_baseline and layer in assistant_baseline:\n",
    "                avg_vector = avg_vector - assistant_baseline[layer]\n",
    "                \n",
    "            role_vectors[role][layer] = avg_vector\n",
    "            \n",
    "    output_path = output_dir / f\"role_vectors_{metric_name}.pkl\"\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        pickle.dump(role_vectors, f)\n",
    "    print(f\"Saved {metric_name} to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_with_sys.empty:\n",
    "    # 1) at_role_period\n",
    "    metric = \"at_role_period\"\n",
    "    baseline = get_assistant_baseline(df_with_sys, metric)\n",
    "    compute_and_save_metric(df_with_sys, metric, metric, filter_deviations=False, assistant_baseline=baseline)\n",
    "\n",
    "    # 2) at_role\n",
    "    metric = \"at_role\"\n",
    "    baseline = get_assistant_baseline(df_with_sys, metric)\n",
    "    compute_and_save_metric(df_with_sys, metric, metric, filter_deviations=False, assistant_baseline=baseline)\n",
    "\n",
    "    # 3) avg_response (Filtered)\n",
    "    metric = \"avg_response\"\n",
    "    baseline = get_assistant_baseline(df_with_sys, metric)\n",
    "    compute_and_save_metric(df_with_sys, metric, metric, filter_deviations=True, assistant_baseline=baseline)\n",
    "\n",
    "    # 4) avg_response_first_10_tokens (Filtered)\n",
    "    metric = \"avg_response_first_10_tokens\"\n",
    "    baseline = get_assistant_baseline(df_with_sys, metric)\n",
    "    compute_and_save_metric(df_with_sys, metric, metric, filter_deviations=True, assistant_baseline=baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f394255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) avg_response (with_sys - without_sys)\n",
    "df_without_sys = load_activations(ACTIVATIONS_DIR, \"without_sys\")\n",
    "\n",
    "if df_without_sys.empty:\n",
    "    print(\"ERROR: df_without_sys is empty!\")\n",
    "else:\n",
    "    parsed_wo = df_without_sys[\"filename_stem\"].apply(lambda x: parse_role_task(x, known_roles, known_tasks))\n",
    "    df_without_sys[\"role\"] = parsed_wo.apply(lambda x: x[0])\n",
    "    df_without_sys[\"task\"] = parsed_wo.apply(lambda x: x[1])\n",
    "\n",
    "    print(f\"Loaded {len(df_without_sys)} without_sys activations.\")\n",
    "\n",
    "    if not df_with_sys.empty:\n",
    "        metric = \"avg_response\"\n",
    "        merged_sys = pd.merge(\n",
    "            df_with_sys[[\"role\", \"task\", \"sample_idx\", \"layer\", metric]],\n",
    "            df_without_sys[[\"role\", \"task\", \"sample_idx\", \"layer\", metric]],\n",
    "            on=[\"role\", \"task\", \"sample_idx\", \"layer\"],\n",
    "            suffixes=(\"_with\", \"_without\")\n",
    "        )\n",
    "\n",
    "        print(f\"Merged {len(merged_sys)} pairs for system prompt diff.\")\n",
    "\n",
    "        merged_sys[\"diff\"] = merged_sys[f\"{metric}_with\"] - merged_sys[f\"{metric}_without\"]\n",
    "\n",
    "        role_vectors_diff = {}\n",
    "        roles = merged_sys[\"role\"].unique()\n",
    "        layers = merged_sys[\"layer\"].unique()\n",
    "\n",
    "        for role in tqdm(roles, desc=\"Computing avg_response_diff\"):\n",
    "            role_vectors_diff[role] = {}\n",
    "            role_df = merged_sys[merged_sys[\"role\"] == role]\n",
    "            \n",
    "            for layer in layers:\n",
    "                layer_data = role_df[role_df[\"layer\"] == layer][\"diff\"]\n",
    "                if layer_data.empty:\n",
    "                    continue\n",
    "                    \n",
    "                vectors = np.stack(layer_data.values)\n",
    "                avg_vector = np.mean(vectors, axis=0)\n",
    "                role_vectors_diff[role][layer] = avg_vector\n",
    "\n",
    "        output_path = OUTPUT_DIR / \"role_vectors_avg_response_sys_diff.pkl\"\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            pickle.dump(role_vectors_diff, f)\n",
    "        print(f\"Saved avg_response_sys_diff to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
